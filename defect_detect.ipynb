{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcXTA6wR5PMC",
        "outputId": "937371a0-d62c-4712-aa73-0994a047dc1a"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "msE9T8n-5VYv"
      },
      "outputs": [],
      "source": [
        "# Directory paths\n",
        "\n",
        "train_dir = '/home/topister/Desktop/ML/GroupAssignment1/Transfer Learning/NEU Metal Surface Defects Data/train'\n",
        "valid_dir = '/home/topister/Desktop/ML/GroupAssignment1/Transfer Learning/NEU Metal Surface Defects Data/train'\n",
        "test_dir = '/home/topister/Desktop/ML/GroupAssignment1/Transfer Learning/NEU Metal Surface Defects Data/test'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qGJQVQ36GxE"
      },
      "source": [
        "# Step 1: Preprocessing the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "g58cO2NFdjWs"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "# import tensorflow as tf\n",
        "# import matplotlib.pyplot as plt\n",
        "# import matplotlib.gridspec as gridspec\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Input\n",
        "from keras.applications import VGG19\n",
        "from keras.layers import Flatten, Dense, Dropout\n",
        "# from keras.preprocessing import image\n",
        "# import numpy as np\n",
        "# import os\n",
        "# from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RDDGlvZ0dldW"
      },
      "outputs": [],
      "source": [
        "CLASSES = 6       # There are 6 classes of defects in each directory: Crazing, Inclusion, Patches, Pitted, Rolled, Scratches\n",
        "HEIGHT = 224      # Height of the input image for the model\n",
        "WIDTH = 224       # Width of the input image for the model\n",
        "CHANNELS = 3      # Number of color channels in the image (RGB - Red, Green, Blue)\n",
        "BATCH_SIZE = 16   # Number of images processed in a single batch during training or inference\n",
        "Epochs = 5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Tqzgh7QMeBUP"
      },
      "outputs": [],
      "source": [
        "# Create a VGG19 model pre-trained on ImageNet without including the top classification layers\n",
        "baseModel = VGG19(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(WIDTH, HEIGHT, CHANNELS)))\n",
        "\n",
        "# Set all layers in the base VGG19 model to non-trainable (freeze the weights)\n",
        "for layer in baseModel.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create a Sequential model to stack layers on top of the pre-trained VGG19 base model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the pre-trained VGG19 base model to the sequential model\n",
        "model.add(baseModel)\n",
        "\n",
        "# Flatten the output from the base model before passing it to fully connected layers\n",
        "model.add(Flatten(name=\"flatten\"))\n",
        "\n",
        "# Add a fully connected dense layer with 1024 units and ReLU activation function\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "\n",
        "# Apply dropout regularization to the previous layer to prevent overfitting (dropout rate: 0.5)\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Add another fully connected dense layer with 256 units and ReLU activation function\n",
        "model.add(Dense(256, activation='relu'))\n",
        "\n",
        "# Apply dropout regularization to the previous layer (dropout rate: 0.5)\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Add the output layer with 'CLASSES' number of units and softmax activation for multi-class classification\n",
        "model.add(Dense(CLASSES, activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PySDLPFgeJ5X",
        "outputId": "c6806c3c-6ef8-4bc9-bf9f-b7c99345d6a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg19 (Functional)          (None, 7, 7, 512)         20024384  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1024)              25691136  \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               262400    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 45979462 (175.40 MB)\n",
            "Trainable params: 25955078 (99.01 MB)\n",
            "Non-trainable params: 20024384 (76.39 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Display a summary of the neural network model architecture, showing the layer names, output shapes,\n",
        "# and the number of parameters in each layer\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "TSy9sVQmeOnZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Data augmentation and normalization for the training dataset\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,              # Rescale pixel values to [0,1]\n",
        "    rotation_range=20,           # Randomly rotate images within 20 degrees\n",
        "    shear_range=0.2,             # Apply shear transformation\n",
        "    zoom_range=0.2,              # Apply random zoom\n",
        "    horizontal_flip=True,        # Flip images horizontally\n",
        "    vertical_flip=True           # Flip images vertically\n",
        ")\n",
        "\n",
        "# Data augmentation and normalization for the validation dataset\n",
        "valid_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,              # Rescale pixel values to [0,1]\n",
        "    rotation_range=20,           # Randomly rotate images within 20 degrees\n",
        "    shear_range=0.2,             # Apply shear transformation\n",
        "    zoom_range=0.2,              # Apply random zoom\n",
        "    horizontal_flip=True,        # Flip images horizontally\n",
        "    vertical_flip=True           # Flip images vertically\n",
        ")\n",
        "\n",
        "# Normalization for the test dataset (no data augmentation for test data)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)  # Rescale pixel values to [0,1] for test data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NinvxpKeXSL",
        "outputId": "8797de78-3f9f-4e55-82a5-2987c425a142"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1656 images belonging to 6 classes.\n",
            "Found 1656 images belonging to 6 classes.\n",
            "Found 72 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "# Generating batches of preprocessed images and their labels using flow_from_directory\n",
        "\n",
        "# Training set generator\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "    train_dir,                      # Directory containing training images\n",
        "    target_size=(WIDTH, HEIGHT),    # Resizes images to match model input dimensions\n",
        "    batch_size=BATCH_SIZE,          # Size of the batches of data (number of samples per gradient update)\n",
        "    class_mode='categorical'        # Uses categorical labels for multi-class classification\n",
        ")\n",
        "\n",
        "# Validation set generator\n",
        "validation_set = valid_datagen.flow_from_directory(\n",
        "    valid_dir,                      # Directory containing validation images\n",
        "    target_size=(WIDTH, HEIGHT),    # Resizes images to match model input dimensions\n",
        "    batch_size=BATCH_SIZE,          # Size of the batches of data (number of samples per gradient update)\n",
        "    class_mode='categorical'        # Uses categorical labels for multi-class classification\n",
        ")\n",
        "\n",
        "# Test set generator\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "    test_dir,                       # Directory containing test images\n",
        "    target_size=(WIDTH, HEIGHT),    # Resizes images to match model input dimensions\n",
        "    batch_size=BATCH_SIZE,          # Size of the batches of data (number of samples per gradient update)\n",
        "    class_mode='categorical',       # Uses categorical labels for multi-class classification\n",
        "    shuffle=False                   # Disables shuffling to maintain order in the test set\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijXizezuei-W",
        "outputId": "19424e33-e2cd-40f6-9e3d-f97eb6c74776"
      },
      "outputs": [],
      "source": [
        "# Compiling the model with specified loss function, optimizer, and evaluation metrics\n",
        "\n",
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",     # Defines the loss function for categorical classification problems\n",
        "    optimizer=Adam(learning_rate=0.001), # Uses Adam optimizer with a learning rate of 0.001 for model optimization\n",
        "    metrics=[\"accuracy\"]                 # Evaluates model performance using accuracy metric\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZRXHGvhexxT",
        "outputId": "4c2c408f-714f-409a-edd5-afbe3447a12d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "103/103 [==============================] - 802s 8s/step - loss: 3.2886 - accuracy: 0.3841 - val_loss: 0.7420 - val_accuracy: 0.7955\n",
            "Epoch 2/5\n",
            "103/103 [==============================] - 778s 8s/step - loss: 0.9392 - accuracy: 0.6445 - val_loss: 0.4681 - val_accuracy: 0.8641\n",
            "Epoch 3/5\n",
            "103/103 [==============================] - 776s 8s/step - loss: 0.7084 - accuracy: 0.7384 - val_loss: 0.4364 - val_accuracy: 0.8501\n",
            "Epoch 4/5\n",
            "103/103 [==============================] - 798s 8s/step - loss: 0.6382 - accuracy: 0.7665 - val_loss: 0.2923 - val_accuracy: 0.9248\n",
            "Epoch 5/5\n",
            "103/103 [==============================] - 822s 8s/step - loss: 0.5676 - accuracy: 0.7884 - val_loss: 0.2993 - val_accuracy: 0.9150\n"
          ]
        }
      ],
      "source": [
        "# Training the model using the fit method with training and validation data\n",
        "\n",
        "history = model.fit(\n",
        "    training_set,                                  # Training dataset\n",
        "    epochs=Epochs,                                 # Number of training epochs\n",
        "    steps_per_epoch=training_set.samples // BATCH_SIZE,  # Number of steps (batches) per epoch for the training set\n",
        "    validation_data=validation_set,                # Validation dataset\n",
        "    validation_steps=validation_set.samples // BATCH_SIZE  # Number of steps (batches) per epoch for the validation set\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "yNOB37Dge6jq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 17s 3s/step - loss: 0.3296 - accuracy: 0.9306\n",
            "5/5 [==============================] - 17s 3s/step - loss: 0.3296 - accuracy: 0.9306\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the trained model using the test dataset\n",
        "\n",
        "scores = model.evaluate(test_set)  # Evaluates the model's performance on the test set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss:  0.32958194613456726\n"
          ]
        }
      ],
      "source": [
        "# Printing the test loss value\n",
        "\n",
        "print('Test Loss: ', scores[0])  # Prints the computed test loss value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy:  0.9305555820465088\n"
          ]
        }
      ],
      "source": [
        "# Printing the test accuracy\n",
        "\n",
        "print('Test Accuracy: ', scores[1])  # Prints the computed test accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ATntDF0BgOs3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# Saving the trained model\n",
        "\n",
        "model.save('defect_detection_model.h5')  # Saves the trained model to a file named 'defect_detection_model.h5'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Dyb9KbQwinB5"
      },
      "outputs": [],
      "source": [
        "# Function to load an image using PIL library\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "def load_image(image_path): # Importing the Image module from the PIL library\n",
        "\n",
        "    \"\"\"\n",
        "    Loads an image using the PIL library.\n",
        "    \n",
        "    Args:\n",
        "    - image_path: The file path of the image to be loaded\n",
        "    \n",
        "    Returns:\n",
        "    - img: The loaded image object\n",
        "    \"\"\"\n",
        "\n",
        "    img = Image.open(image_path)\n",
        "    return img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "y0k7aMovisuV"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from keras.preprocessing.image import img_to_array\n",
        "\n",
        "def preprocess_image(img):\n",
        "    # Resize the image to the required input size (224x224 for VGG16)\n",
        "    img = img.resize((224, 224))\n",
        "\n",
        "    # Convert the image to RGB if it has a single channel (grayscale)\n",
        "    if img.mode != 'RGB':\n",
        "        img = img.convert('RGB')\n",
        "\n",
        "    # Convert PIL Image to numpy array\n",
        "    img_array = img_to_array(img)\n",
        "\n",
        "    # Normalize pixel values to be in the range [0, 1]\n",
        "    img_array = img_array / 255.0\n",
        "\n",
        "    return img_array\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "mXD2Tynzhbh-"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = load_model('defect_detection_model.h5')\n",
        "\n",
        "\n",
        "# Use the loaded model to make predictions on new data\n",
        "def detect_defect(image_path):\n",
        "    img = load_image(image_path)  # Load the image (implement this function)\n",
        "    img = preprocess_image(img)   # Preprocess the image (implement this function)\n",
        "\n",
        "    # Make predictions using the loaded model\n",
        "    prediction = loaded_model.predict(np.expand_dims(img, axis=0))\n",
        "\n",
        "    # Check the prediction result\n",
        "    if prediction[0][0] >= 0.5:  # Assuming binary classification (defect or non-defect)\n",
        "        return \"Defect Detected\"\n",
        "    else:\n",
        "        return \"No Defect Detected\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ! pip install opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2  # Import OpenCV for image manipulation\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = load_model('defect_detection_model.h5')\n",
        "\n",
        "# Use the loaded model to make predictions on new data\n",
        "def detect_defect(image_path):\n",
        "    img = load_image(image_path)  # Load the image (implement this function)\n",
        "    img = preprocess_image(img)  # Preprocess the image (implement this function)\n",
        "\n",
        "    # Make predictions using the loaded model\n",
        "    prediction = loaded_model.predict(np.expand_dims(img, axis=0))\n",
        "\n",
        "    # Check the prediction result\n",
        "    if prediction[0][0] >= 0.5:  # Assuming binary classification (defect or non-defect)\n",
        "        result = \"Defect Detected\"\n",
        "    else:\n",
        "        result = \"No Defect Detected\"\n",
        "\n",
        "    # Display the image and the result\n",
        "    plt.imshow(cv2.imread(image_path))  # Show the original image\n",
        "    plt.title(result)\n",
        "    plt.axis('off')  # Hide axis labels\n",
        "    plt.show()\n",
        "\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example usage\n",
        "\n",
        "image_path = '/home/topister/Desktop/ML/GroupAssignment1/Transfer Learning/NEU Metal Surface Defects Data/test/Crazing/Cr_1.bmp'  # Replace with your image path\n",
        "detection_result = detect_defect(image_path)\n",
        "print(\"Detection Result:\", detection_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smRNpBqYiv7J"
      },
      "outputs": [],
      "source": [
        "# # Replace 'test_image.jpg' with the path to your test image\n",
        "# test_image_path = '/content/drive/My Drive/ML/Transfer Learning/NEU Metal Surface Defects Data/test/Crazing/Cr_109.bmp'\n",
        "\n",
        "# result = detect_defect(test_image_path)\n",
        "# print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pERRkizojSY4"
      },
      "outputs": [],
      "source": [
        "# # Replace 'test_image.jpg' with the path to your test image\n",
        "# test_image_path = '/content/drive/My Drive/ML/Transfer Learning/NEU Metal Surface Defects Data/test/Crazing/Cr_108.bmp'\n",
        "\n",
        "# result = detect_defect(test_image_path)\n",
        "# print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6de9Glpk5yb"
      },
      "outputs": [],
      "source": [
        "# # Replace 'test_image.jpg' with the path to your test image\n",
        "# test_image_path = '/content/drive/My Drive/ML/Transfer Learning/NEU Metal Surface Defects Data/test/Crazing/Cr_104.bmp'\n",
        "\n",
        "# result = detect_defect(test_image_path)\n",
        "# print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xny8AXbzk_gd"
      },
      "outputs": [],
      "source": [
        "# # Replace 'test_image.jpg' with the path to your test image\n",
        "# test_image_path = '/content/drive/My Drive/ML/Transfer Learning/NEU Metal Surface Defects Data/train/Rolled/RS_183.bmp'\n",
        "\n",
        "# result = detect_defect(test_image_path)\n",
        "# print(result)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lp9xKMRJsGZG"
      },
      "outputs": [],
      "source": [
        "# # Replace 'test_image.jpg' with the path to your test image\n",
        "# test_image_path = '/content/drive/My Drive/ML/Transfer Learning/img064.jpg'\n",
        "\n",
        "# result = detect_defect(test_image_path)\n",
        "# print(result)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2tB0fW4TcIE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
